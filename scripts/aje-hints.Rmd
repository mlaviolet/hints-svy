---
title: "Analyzing the HINTS Survey with R"
author: "ML"
date: "`r format(Sys.time(), '%Y-%m-%d, %H:%M')`"
output:
  html_document: default
  word_document: default
  pdf_document: default
bibliography: references.bib
csl: american-journal-of-epidemiology.csl
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Abstract

The Health Information National Trends Survey (HINTS) is conducted by the National Cancer Institute (NCI) to collect nationally representative data about the American public's knowledge of, attitudes toward, and use of cancer- and health-related information. NCI provides supporting documentation and public-use data formatted for the proprietary systems SAS, SPSS, and Stata. The free, open-source R software has all functionality needed to analyze HINTS data, but NCI does not currently provide support for R users. This article demonstrates how R can be used to analyze HINTS data with examples drawn from HINTS documentation and published research.

### Introduction

#### About HINTS

The Health Information National Trends Survey (HINTS) is conducted by the National Cancer Institute (NCI) to regularly collect nationally representative data about the American public's use of cancer-related information (CITE). HINTS topics include looking for health information from the Internet and other sources, personal health care, caregiving, clinical trials, nutrition, physical activity, cancer screening and awareness, beliefs about cancer, and cancer history.

HINTS data with supporting documentation, including analysis examples, are available to the public. Currently this material is available only for the most common propietary statistical software systems: SAS, SPSS, and Stata. This article aims to demonstrate that analysis can be conducted using the free, open-source environment R (CITE), and thus make these valuable data useful to analysts without access to expensive proprietary software.

The HINTS target population is civilian, non-institutionalized adults aged 18 or older living in the United States. The most recent version of HINTS administration (referred to as HINTS 5) included four data collection cycles over the course of four years. Except for Cycle 3, the primary data collection was a mail-based survey with random sampling in a complex sampling frame design (CITE). For Cycle 3, a subset of participants were sampled from the same frame and also recruited by mail but were given the option of a web-based survey using one of two different types of web-based administration. Implications for analysis of Cycle 3 are discussed later.

(CITE Cycle 4 Methodology Report)

For each adult, person-level weights and a set of 50 replicate weights are provided. These replicate weights are used to calculate variance estimates (e.g. standard errors and confidence intervals) using the delete one jackknife (JK1) replication method. Replication is the recommended method for variance estimation for HINTS, but some software packages (SPSS) lack a replication option and only support variance estimation via Taylor series linearization. Although HINTS data files provide the appropriate variables to do so, in this article we limit attention to replication.

(CITE reference to replicate weights)

### About R

R (CITE) is a free software environment for statistical computing and graphics. It compiles and runs on a wide variety of platforms, including Microsoft Windows, MacOS, and major Linux distributions. At this writing, the current version is 4.2.1, released June 2022. R is typically run under an integrated development environment; the most popular is RStudio (CITE).

Unlike the procedure-oriented languages SAS, SPSS, and Stata, R works by creating objects, best described as data structures which can be manipulated and from which data and other information can be extracted. For example, linear regression is done by creating an object which contains model coefficients, fitted values, residuals, significance test results, and other information about the fitted model. These data can be extracted and processed as needed. Objects are created and processed by functions; for example; `summary(df)` will produce a numerical summary or tally of each variable in the data set `df`.

Resources for learning R include the books by Wickham and Grolemund [@wickham2016] and Lander [@lander2017].

Functionality of R is expanded by nearly 19,000 user-contributed add-on packages. Analysis of complex surveys is accomplished by the `{survey}` package, which provides functionality comparable to SUDAAN (CITE) and provides summary statistics, generalized linear models, and other analyses for multistage stratified, cluster-sampled, unequally weighted survey samples. With this package the user constructs a survey object which contains the survey data and all survey design specifications, such as primary sampling units, strata, and weights. Analyses are performed by specifying the analysis type desired and referencing the survey object. Unlike SAS and SUDAAN, it is not necessary to specify the survey design for each analysis.

The `{srvyr}` package uses functions from `{survey}` to work seamlessly with the popular `{tidyverse}` suite of packages, which have become the tools of choice for data science in recent years. The `{srvyr}` package can produce data sets of summary statistics. For model fitting, the `{broom}` and `{broom.helpers}` package produce data sets of results for convenient manipulation.

To begin an analysis, we launch RStudio, then install and load the necessary packages. Installation is generally done only once.

```{r install_packages, eval = FALSE}
install.packages(c("tidyverse", "survey", "srvyr", "svyVGAM", "broom", 
                  "broom.helpers", "haven", "flextable", "here"))
```

Packages are available for use once loaded.

```{r load_packages, message=FALSE}
library(tidyverse)
library(survey)
library(srvyr)
library(svyVGAM)
library(broom)
library(broom.helpers)
library(haven)
library(flextable)
library(here)
```

### Replicating results from HINTS documentation

We begin by replicating results from the HINTS documentation (hereafter "guidelines") for HINTS 5 Cycle 4, for which data were collected between February and May 2020. For each survey cycle, data and documentation are distributed in compressed files  with data formatted for SAS, SPSS, or Stata. R can import each of these formats with the `{haven}`package. We begin by importing the SAS data and recoding the variables of interest. The final step in the sequence below is to construct the replicate survey object with analysis weight `PERSON_FINWT0` and replicate weights `PERSON_FINWT1` through `PERSON_FINWT150`.

```{r import}
# education levels
edu_lbl <- c("Less than high school",
             "12 years or completed high school",
             "Some college",
             "College graduate or higher")
# general health status
health_lbl <- c("Excellent", "Very good", "Good", "Fair", "Poor")
# convenience function to show percentages to four places like SAS
percent <- function(x) 100 * x

# import SAS data set directly from .zip file
hints5_4_rep <- read_sas(
  unz(here("data-raw", "HINTS5_Cycle4_SAS_20220519.zip"),
      "HINTS5_Cycle4_SAS_20220519/hints5_cycle4_public.sas7bdat")) %>% 
  mutate(# code BirthGender as binary male-female
    gender = factor(BirthGender, 1:2, c("Male", "Female")),
    # recode negative GeneralHealth values to missing
    GeneralHealth = if_else(GeneralHealth < 0, NA_real_, GeneralHealth),
    # collapse education to four levels
    edu = case_when(Education %in% 1:2 ~ 1, # less than high school
                    Education == 3     ~ 2, # high school or equivalent
                    Education %in% 4:5 ~ 3, # some college
                    Education %in% 6:7 ~ 4, # college graduate
                    TRUE ~ NA_real_)) %>% 
  # change edu from numeric to factor
  mutate(edu = factor(edu, levels = 1:4, labels = edu_lbl),
         # "No" must be the referent level of SeekCancerInfo to model the 
         #   probability of "Yes". By default the first level of a factor is 
         #   the referent level, so reversing the order of levels makes 
         #   "No" the referent.
         SeekCancerInfo = factor(SeekCancerInfo, levels = 2:1, 
                                 labels = c("No", "Yes"))) %>% 
  # construct replicate weights survey object
  as_survey_rep(weights = "PERSON_FINWT0",
                repweights = paste0("PERSON_FINWT", 1:50),
                type = "JK1", scale = 49/50, mse = TRUE)

```

#### Frequency tables

The following code produces the frequency table of gender and educational attainment on page 10 of the guidelines

```{r freq_table}
tbl_1 <- hints5_4_rep %>% 
  # remove missings in either table variable to get correct unweighted 
  #   sample sizes
  filter(!is.na(edu), !is.na(gender)) %>% 
  # compute unweighted sample sizes by education level and gender
  group_by(gender, edu) %>% 
  # compute unweighted sample sizes and weighted percentage with standard
  #   errors and confidence intervals
  summarize(n = unweighted(n()),
            pct = survey_mean(na.rm = TRUE, vartype = c("se", "ci"))) %>% 
  drop_na() %>% 
  mutate(across(starts_with("pct"), percent))

flextable(tbl_1) %>% 
  colformat_double(digits = 2) %>% 
  set_header_labels(gender = "Gender", edu = "Education", n = "n", 
                    pct = "Percent", pct_se = "Std. Err.", 
                    pct_low = "95% LCI", pct_upp = "95% UCI") %>% 
  autofit()

```

Using the `svychisq()` function from `{survey}` we conduct the chi-square test of association between gender and education. We feed the resulting object to the `tidy()` function from the `{broom}` to put the results in a data set for subsequent processing if desired.

```{r chi_square, message=FALSE, warning=FALSE}
wald <- svychisq(~ edu + gender, hints5_4_rep, statistic = "Wald") %>% 
  tidy() %>% 
  mutate(method = "Wald test of association")
adj_wald <- svychisq(~ edu + gender, hints5_4_rep, statistic = "adjWald") %>% 
  tidy() %>% 
  mutate(method = "Adjusted Wald test of association")
  
bind_rows(wald, adj_wald) %>%
  mutate(across(c(statistic, p.value), ~ signif(.x, 3))) %>%
  flextable() %>% 
  colformat_double(j = 3, digits = 2) %>% 
  colformat_double(j = 4, digits = 4) %>% 
  set_header_labels(ndf = "Num DF", ddf = "Den DF", statistic = "F statistic",
                    p.value = "P value", method = "Method") %>%
  autofit()
```

#### Logistic regression

This example demonstrates a multivariable logistic regression model using the `svyglm()` function. To construct a data table of results, we use functions from the `{broom}` and `{broom.helpers}` packages to put the results in "tidy" format.

```{r logistic}
model_logit <- svyglm(SeekCancerInfo ~ gender + edu, hints5_4_rep, 
       family = quasibinomial) 
# functions from {broom.helpers}
model_logit %>% 
  tidy_and_attach(exp = TRUE) %>% 
  tidy_remove_intercept() %>% 
  tidy_add_term_labels() %>% 
  select(label, or = estimate, p.value, or_low = conf.low, 
         or_upp = conf.high) %>% 
  mutate(p.value = round(p.value, digits = 3)) %>% 
  flextable() %>% 
  colformat_double(j = c(2, 4, 5), digits = 2) %>% 
  colformat_double(j = 3, digits = 3) %>% 
  set_header_labels(label = "Model term", or = "Odds ratio", p.value = "P-value",
          or_low = "95% LCI", or_upp = "95% UCI") %>%
  autofit()
```

As previously noted, the HINTS data sets contain a set of 50 replicate weights to compute accurate standard errors for statistical testing procedures. These replicate weights were created using a jackknife minus one replication method; thus when analyzing one iteration or group of HINTS data, the proper denominator degrees of freedom (ddf) is 49. To perform the Type 3 analysis of effects for the logistic regression model, we use the function `regTermTest()`. The `{broom}` package does not currently support tidying the resulting objects.

```{r effect_tests}
# test for gender effect
regTermTest(model_logit, ~ gender, df = 49)
# test for education effect
regTermTest(model_logit, ~ edu, df = 49)
```

#### Relative risk regression

At this point we present an alternative analysis using relative risk regression using the log link instead of logistic regression using the logit link. While the mathematics of logistic regression is relatively straightforward, the resulting odds ratios are easily misinterpreted, especially by lay readers. This issue has been extensively discussed; see for example Osborne [@osborne]. We perform a relative risk regression following recommendations of Lumley [@lumley2010]. 

```{r log_link}
# Using the log link requires starting values for the estimates. Lumley 
#   recommends using -0.5 for the intercept and zero for each regression term
#   (in this case there are four).
model_rr <- svyglm(SeekCancerInfo ~ gender + edu, hints5_4_rep, 
       family = quasibinomial(log), start = c(-0.5, rep(0, 4))) 
model_rr %>% 
  tidy_and_attach(exp = TRUE) %>% 
  tidy_remove_intercept() %>% 
  tidy_add_term_labels() %>% 
  select(label, rr = estimate, p.value, rr_low = conf.low, 
         rr_upp = conf.high) %>% 
  mutate(p.value = round(p.value, digits = 3)) %>% 
  flextable() %>% 
  colformat_double(j = c(2, 4, 5), digits = 2) %>% 
  colformat_double(j = 3, digits = 3) %>% 
  set_header_labels(label = "Model term", rr = "Risk ratio", p.value = "P-value",
          rr_low = "95% LCI", rr_upp = "95% UCI") %>%
  autofit()
  
```
Note that since the outcome values are not constrained to the unit interval with a log link, the analyst should check the results. The `augment()` function produces a record-level data set with fitted values, residuals, and other diagnostics. For survey models, the function produces a warning, but I have encountered no issues. The following check shows no fitted probabilities greater than one.

```{r check_rr}
augment(model_rr) %>% 
  count(exp(.fitted) > 1)
```

With the relative risk regression, we can make such statements as "women are between five percent and 39 percent more likely than men to look for information about cancer from any source."

### Linear regression

Following the guidelines, for the purpose of discussion we treat `General Health` as a quantitative variable.

```{r}
# pp. 13-14
model_lin <- svyglm(GeneralHealth ~ gender + edu, hints5_4_rep)
model_lin %>% 
  tidy_and_attach() %>% 
  tidy_remove_intercept() %>% 
  tidy_add_term_labels() %>% 
  select(label, estimate, std.error, conf.low, conf.high, p.value) %>% 
  mutate(p.value = round(p.value, digits = 3)) %>% 
  flextable() %>% 
  colformat_double(j = c(2:5), digits = 4) %>% 
  colformat_double(j = 6, digits = 3) %>% 
  set_header_labels(label = "Model term", estimate = "Coefficient",
          std.error = "Std. Err.", conf.low = "95% LCI", conf.high = "95% UCI",
                    p.value = "P-value") %>%
  autofit()

```

```{r lin_effects}
regTermTest(model_lin, ~ gender + edu)
regTermTest(model_lin, ~ gender)
regTermTest(model_lin, ~ edu)

```



### Replicating results from published research

Drawing examples from Kiviniemi et al [@kiviniemi2021].

### References

Overview of the HINTS 5 Cycle 4 (2020) survey and data analysis recommendations
