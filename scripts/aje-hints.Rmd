---
title: "Analyzing the HINTS Survey with R"
author: "ML"
date: "`r format(Sys.time(), '%Y-%m-%d, %H:%M')`"
output:
  word_document: default
  pdf_document: default
  html_document: default
bibliography: references.bib
csl: american-journal-of-epidemiology.csl
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Abstract

The Health Information National Trends Survey (HINTS) is conducted by the National Cancer Institute (NCI) to collect nationally representative data about the American public's knowledge of, attitudes toward, and use of cancer- and health-related information. NCI provides supporting documentation and public-use data formatted for the proprietary systems SAS, SPSS, and Stata. The free, open-source R software has all functionality needed to analyze HINTS data, but NCI does not currently provide support for R users. This article demonstrates how R can be used to analyze HINTS data with examples drawn from HINTS documentation and published research.

#### Introduction

The Health Information National Trends Survey (HINTS) is conducted by the National Cancer Institute (NCI) to regularly collect nationally representative data about the American public's use of cancer-related information [@healthi]. HINTS topics include looking for health information from the Internet and other sources, personal health care, caregiving, clinical trials, nutrition, physical activity, cancer screening and awareness, beliefs about cancer, and cancer history. Recent publications using HINTS data include [@langford2022], [@sacca2022], and [@kiviniemi2021].

HINTS data with supporting documentation, including analysis examples, are available to the public. Currently this material is available only for the most common proprietary statistical software systems: SAS [@sas], SPSS [@spsssta], and Stata [@statisti]. This article aims to demonstrate that HINTS analysis can be conducted using the free, open-source system R [@rcoreteam2021], and thus make these valuable data useful to analysts without access to expensive proprietary software.

#### About HINTS

The HINTS target population is civilian, non-institutionalized adults aged 18 or older living in the United States. The most recent version of HINTS administration (referred to as HINTS 5) included four data collection cycles conducted between 2017 and 2020 [@methodol]. Except for Cycle 3, the primary data collection was a mail-based survey with random sampling in a complex sampling frame design. For Cycle 3 a subset of participants were sampled and recruited by mail, but certain respondents were given the option of a web-based survey using one of two different types of web-based administration. Implications for analysis of Cycle 3 are discussed later.

For each adult, person-level weights and a set of 50 replicate weights are provided. These replicate weights are used to calculate variance estimates the delete one jackknife (JK1) replication method [@heeringa2017] (pp. 75-89). Replication is the recommended method for variance estimation, but SPSS lacks a replication option and only supports variance estimation via Taylor series linearization. Although HINTS data files provide the appropriate variables to do so, in this article we limit attention to replication.

### About R

R is a free software environment for statistical computing and graphics. It compiles and runs on a wide variety of platforms, including Microsoft Windows, MacOS, and major Linux distributions. At this writing, the current version is 4.2.1, released June 2022. R is typically run under an integrated development environment; the most popular is RStudio [@rstudio].

Unlike the procedure-oriented languages SAS, SPSS, and Stata, R works by creating objects, best described as data structures which can be manipulated and from which data and other information can be extracted. For example, linear regression is done by creating an object which contains model coefficients, fitted values, residuals, significance test results, and other information about the fitted model. These data can be extracted and processed as needed. Objects are created and processed by functions; for example; `summary(df)` will produce a numerical summary or tally of each variable in the data set `df`. Various arguments control how the function operates; for example, `mean(df$x, na.rm = TRUE)` will compute the mean of the variable `x` in the data set `df`, omitting missing values. Resources for learning R include online tutorials and courses such as [@rtutori], [@rforth], and books by Wickham and Grolemund [@wickham2016] and Lander [@lander2017].

Functionality of R is expanded by nearly 19,000 user-contributed add-on packages. Analysis of complex surveys is accomplished by the `{survey}` package [@lumley2021], which provides functionality comparable to SUDAAN [@sudaan] and provides summary statistics, generalized linear models, and other analyses for multistage stratified, cluster-sampled, unequally weighted survey samples. With this package the user constructs a survey object which contains the survey data and all survey design specifications, such as primary sampling units, strata, and weights. Analyses are performed by specifying the analysis type desired and referencing the survey object. Unlike SAS and SUDAAN, it is not necessary to specify the survey design for each analysis.

The `{srvyr}` package [@ellis2021] uses functions from `{survey}` to work seamlessly with the popular `{tidyverse}` [@wickham2019] suite of packages, which have become the tools of choice for data science in recent years. The `{srvyr}` package can produce data sets of summary statistics. For model fitting, the `{broom}` [@robinson2022] and `{broom.helpers}` [@larmarange2022] packages format analysis reports into data tables for convenient manipulation.

Packages are installed to the user's system, typically only once, then loaded as needed. To begin an analysis launch RStudio, then install (if needed) and load the necessary packages.

```{r install_packages, eval = FALSE}
install.packages(c("tidyverse", "survey", "srvyr", "broom", 
                  "broom.helpers", "haven"))
```

```{r show_packages, eval=FALSE}
library(tidyverse)
library(survey)
library(srvyr)
library(broom)
library(broom.helpers)
library(haven)
```

```{r load_packages, include=FALSE, message=FALSE}
library(tidyverse)
library(survey)
library(srvyr)
library(broom)
library(broom.helpers)
library(haven)
library(flextable)
library(here)
```

### Replicating results from HINTS documentation

For each survey cycle, data and documentation are distributed in compressed files with data formatted for SAS, SPSS, or Stata [@download]. For HINTS 5 Cycle 4, analysis guidelines are contained in the document "Overview of the HINTS 5 Cycle 4 (2020) Survey and Data Analysis Recommendations" (hereafter "guidelines"). R can import any of the three provided formats with the `{haven}`package. We begin by importing the SAS data.

```{r import_show, eval=FALSE}
hints5_4_rep <- read_sas(
  unz("HINTS5_Cycle4_SAS_20220519.zip",
      "HINTS5_Cycle4_SAS_20220519/hints5_cycle4_public.sas7bdat"))
```

```{r import, echo=FALSE}
hints5_4_rep <- read_sas(
  unz(here("data-raw", "HINTS5_Cycle4_SAS_20220519.zip"),
      "HINTS5_Cycle4_SAS_20220519/hints5_cycle4_public.sas7bdat"))
```

Next we recode the variables of interest. The final step in the sequence below is to construct the replicate survey object with analysis weight `PERSON_FINWT0` and replicate weights `PERSON_FINWT1` through `PERSON_FINWT150`.

```{r recode}
# four-level educational attainment
edu_lbl <- c("Less than high school",
             "12 years or completed high school",
             "Some college",
             "College graduate or higher")

# import SAS data set directly from .zip file
hints5_4_rep <- hints5_4_rep %>% 
  mutate(
    # code BirthGender as binary male-female
    gender = factor(BirthGender, 1:2, c("Male", "Female")),
    # recode negative GeneralHealth values to missing
    GeneralHealth = if_else(GeneralHealth < 0, NA_real_, GeneralHealth),
    # collapse education to four levels
    edu = case_when(Education %in% 1:2 ~ 1, # less than high school
                    Education == 3     ~ 2, # high school or equivalent
                    Education %in% 4:5 ~ 3, # some college
                    Education %in% 6:7 ~ 4, # college graduate
                    TRUE ~ NA_real_)) %>% 
  # change edu from numeric to factor
  mutate(edu = factor(edu, levels = 1:4, labels = edu_lbl)) %>% 
  # SeekCancerInfo will be used as the outcome in a logistic regression. To
  #   model the probability of "Yes", "No" must be the referent level. By
  #   default the first level of a factor is the referent level, so we
  #   reversing the order of levels.
  mutate(SeekCancerInfo = factor(SeekCancerInfo, levels = 2:1, 
                                 labels = c("No", "Yes"))) %>% 
  # construct replicate weights survey object
  as_survey_rep(weights = "PERSON_FINWT0",
                repweights = paste0("PERSON_FINWT", 1:50),
                type = "JK1", scale = 49/50, mse = TRUE)
```

#### Frequency tables

The following code produces the frequency table of gender and educational attainment on page 10 of the guidelines.

```{r freq_table}
tbl_1 <- hints5_4_rep %>% 
  # remove missings in either table variable to get correct unweighted 
  #   sample sizes
  filter(!is.na(edu), !is.na(gender)) %>% 
  # compute unweighted sample sizes by education level and gender
  group_by(gender, edu) %>% 
  # compute unweighted sample sizes and weighted percentage with standard
  #   errors and confidence intervals
  summarize(n = unweighted(n()),
            pct = survey_mean(na.rm = TRUE, vartype = c("se", "ci"))) %>% 
  drop_na() %>% 
  # survey package reports as proportions, convert to percentage
  mutate(across(starts_with("pct"), ~ 100 * .x))
```
```{r tbl_1, echo=FALSE}
flextable(tbl_1) %>% 
  colformat_double(digits = 2) %>% 
  set_header_labels(gender = "Gender", edu = "Education", n = "n", 
                    pct = "Percent", pct_se = "Std. Err.", 
                    pct_low = "95% LCI", pct_upp = "95% UCI") %>% 
  # line_spacing(space = 1, part = "body")
  autofit()
```
Using the `svychisq()` function from `{survey}` we conduct the chi-square test of association between gender and education. We feed the resulting object to the `tidy()` function from the `{broom}` to put the results in a data set for subsequent processing if desired.

```{r chi_square, message=FALSE, warning=FALSE}
wald <- svychisq(~ edu + gender, hints5_4_rep, statistic = "Wald") %>% 
  tidy() %>% 
  mutate(method = "Wald test of association")
adj_wald <- svychisq(~ edu + gender, hints5_4_rep, statistic = "adjWald") %>% 
  tidy() %>% 
  mutate(method = "Adjusted Wald test of association")
```

```{r chi_square_table, echo=FALSE}
bind_rows(wald, adj_wald) %>%
  relocate(method) %>% 
  mutate(across(c(statistic, p.value), ~ signif(.x, 3))) %>%
  flextable() %>% 
  colformat_double(j = 3, digits = 2) %>% 
  colformat_double(j = 4, digits = 4) %>% 
  set_header_labels(ndf = "Num DF", ddf = "Den DF", statistic = "F statistic",
                    p.value = "P value", method = "Method") %>%
  autofit()
```

#### Logistic regression

This example demonstrates a multivariable logistic regression model using the `svyglm()` function from {survey}. To construct a data table of results, we use functions from the `{broom}` and `{broom.helpers}` packages.

```{r logistic}
model_logit <- svyglm(SeekCancerInfo ~ gender + edu, hints5_4_rep, 
       family = quasibinomial) 
logit_tbl <- model_logit %>% 
  # functions from {broom.helpers}
  tidy_and_attach(exp = TRUE) %>% # exponentiate coefficients to get odds ratios
  tidy_remove_intercept() %>% 
  tidy_add_term_labels() %>% 
  # 
  select(label, or = estimate, p.value, or_low = conf.low, 
         or_upp = conf.high) %>% 
  mutate(p.value = round(p.value, digits = 3))
```
```{r logistic_table, echo=FALSE}
flextable(logit_tbl) %>% 
  colformat_double(j = c(2, 4, 5), digits = 2) %>% 
  colformat_double(j = 3, digits = 3) %>% 
  set_header_labels(label = "Model term", or = "Odds ratio", p.value = "P-value",
          or_low = "95% LCI", or_upp = "95% UCI") %>%
  autofit()
```

As previously noted, the HINTS data sets contain a set of 50 replicate weights to compute accurate standard errors for statistical testing procedures. These replicate weights were created using a jackknife minus one replication method; thus when analyzing one iteration or group of HINTS data, the proper denominator degrees of freedom (ddf) is 49. To perform the Type 3 analysis of effects for the logistic regression model, we use the function `regTermTest()`. The `{broom}` package does not currently support tidying the resulting objects.

```{r effect_tests}
# test for gender effect
regTermTest(model_logit, ~ gender, df = 49)
# test for education effect
regTermTest(model_logit, ~ edu, df = 49)
```

#### Relative risk regression

At this point we present an alternative analysis using relative risk regression using the log link instead of logistic regression using the logit link. While the mathematics of logistic regression are relatively straightforward, the resulting odds ratios are easily misinterpreted, especially by lay readers. This issue has been extensively discussed; see for example Osborne [@osborne]. We perform a relative risk regression following recommendations of Lumley [@lumley2010].

```{r log_link}
# Using the log link requires starting values for the estimates. Lumley 
#   recommends using -0.5 for the intercept and zero for each regression term
#   (in this case there are four).
model_rr <- svyglm(SeekCancerInfo ~ gender + edu, hints5_4_rep, 
       family = quasibinomial(log), start = c(-0.5, rep(0, 4))) 
model_rr_tbl <- model_rr %>% 
  tidy_and_attach(exp = TRUE) %>% 
  tidy_remove_intercept() %>% 
  tidy_add_term_labels() %>% 
  select(label, rr = estimate, p.value, rr_low = conf.low, 
         rr_upp = conf.high) %>% 
  mutate(p.value = round(p.value, digits = 3)) 
```
```{r log_link_tbl}
  flextable(model_rr_tbl) %>% 
  colformat_double(j = c(2, 4, 5), digits = 2) %>% 
  colformat_double(j = 3, digits = 3) %>% 
  set_header_labels(label = "Model term", rr = "Risk ratio", p.value = "P-value",
          rr_low = "95% LCI", rr_upp = "95% UCI") %>%
  autofit()
  
```

Note that since the outcome values are not constrained to the unit interval with a log link, the analyst should check the results. The `augment()` function produces a record-level data set with fitted values, residuals, and other diagnostics. For survey models, the function produces a warning, but I have encountered no issues. The following check shows no fitted probabilities greater than one.

```{r check_rr}
augment(model_rr) %>% 
  count(exp(.fitted) > 1)
```

With the relative risk regression, we can make such statements as "women are between five percent and 39 percent more likely than men to look for information about cancer from any source."

### Linear regression

Following the guidelines, for the purpose of discussion we treat `General Health` as a quantitative variable.

```{r lin_reg}
# pp. 13-14
model_lin <- svyglm(GeneralHealth ~ gender + edu, hints5_4_rep)
model_lin_tbl <- model_lin %>% 
  tidy_and_attach() %>% 
  tidy_remove_intercept() %>% 
  tidy_add_term_labels() %>% 
  select(label, estimate, std.error, conf.low, conf.high, p.value) %>% 
  mutate(p.value = round(p.value, digits = 3)) 
```
```{r lin_reg_tbl}
  flextable(model_lin_tbl) %>% 
  colformat_double(j = c(2:5), digits = 4) %>% 
  colformat_double(j = 6, digits = 3) %>% 
  set_header_labels(label = "Model term", estimate = "Coefficient",
          std.error = "Std. Err.", conf.low = "95% LCI", conf.high = "95% UCI",
                    p.value = "P-value") %>%
  autofit()

```

Here we test for model effects.

```{r lin_effects}
regTermTest(model_lin, ~ gender + edu)
regTermTest(model_lin, ~ gender)
regTermTest(model_lin, ~ edu)

```

### Replicating results from published research

Drawing examples from Kiviniemi et al .

References

Overview of the HINTS 5 Cycle 4 (2020) survey and data analysis recommendations
